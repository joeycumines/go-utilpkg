{
  "policy": "ALL tasks and subtasks contained within this blueprint MUST be completed in their entirety. Deferring, skipping, or omitting any part of the plan is strictly prohibited. Every unit defined here represents a mandatory component of final delivery. 'Effective test coverage' means covering ALL code paths, edge cases, and error conditions - not just line coverage. This includes unreachable paths, error branches, and platform-specific code.",
  "tasks": [
    {
      "id": "RV02",
      "title": "REJECTED: TPS Counter Startup Behavior (Current Implementation Correct)",
      "description": "This task requested adding a 'createdAt' field and warmup logic to suppress TPS to 0.0 during initial window fill. However, after thorough analysis, current TPS counter behavior is CORRECT. TPS should report actual rolling window average, not artificially suppress during warmup. Tests expecting 'TPS=0 during warmup' are incorrect expectations, not missing implementation.",
      "status": "rejected",
      "critical": true,
      "validationDate": "2026-02-02",
      "validationStatus": "REJECTED - Current TPS counter behavior is correct",
      "rejectionReason": "Current TPS counter correctly reports rolling window average without artificial warmup suppression. Tests expecting warmup behavior have incorrect expectations. TPS counter should report actual transaction rate based on samples in rolling window.",
      "dependsOn": [],
      "sourceDocument": "eventloop/review.md",
      "location": "eventloop/metrics.go",
      "deliverables": [],
      "acceptanceCriteria": []
    },
    {
      "id": "RV08",
      "title": "CRITICAL: Fix Invalid Negative Elapsed Test",
      "description": "The current TestTPSCounter_NegativeElapsed is invalid/placebo. It sets lastRotation to the past (Now - 5s), which results in POSITIVE elapsed time. To test negative elapsed (clock rollback), it must set lastRotation to the FUTURE. The test must be updated to correctly simulate a clock jump backwards and verify the counter resets/recovers.",
      "status": "completed",
      "critical": true,
      "dependsOn": [],
      "sourceDocument": "eventloop/review.md",
      "location": "eventloop/metrics_overflow_test.go",
      "deliverables": [
        "Update test to set lastRotation to time.Now().Add(5 * time.Second) (Future)",
        "Verify rotate() logic handles negative elapsed correctly (likely via reset)",
        "Ensure test fails if negative elapsed is not handled"
      ],
      "acceptanceCriteria": [
        "Test correctly simulates negative elapsed time",
        "TPSCounter recovers from negative elapsed without panic or negative values",
        "Test is no longer a placebo"
      ]
    },
    {
      "id": "RV09",
      "title": "CRITICAL: Fix rotate() Time Synchronization Defect",
      "description": "The previous refactor of rotate() removed the 'full window reset' block. If elapsed time exceeds the window size (e.g. sleep/pause), the current logic only advances the clock by one window size, leaving the internal 'lastRotation' permanently lagging behind wall clock time. This causes data loss and reporting errors. The full reset logic must be restored: if bucketsToAdvance >= len(buckets), reset all buckets and set lastRotation = Now.",
      "status": "completed",
      "critical": true,
      "dependsOn": [],
      "sourceDocument": "eventloop/review.md",
      "location": "eventloop/metrics.go",
      "deliverables": [
        "Restore full window reset check in rotate()",
        "If bucketsToAdvance >= len(buckets): Reset all buckets to 0",
        "If bucketsToAdvance >= len(buckets): Set lastRotation = time.Now()",
        "Ensure no persistent lag after long sleep"
      ],
      "acceptanceCriteria": [
        "Counter correctly handles long pauses (>> windowSize)",
        "lastRotation syncs to Now() on full reset",
        "No reporting lag after wake from sleep"
      ]
    },
    {
      "id": "RV10",
      "title": "Fix Integer Overflow in rotate()",
      "description": "The calculation 'int(elapsed / bucketSize)' converts to int (potentially 32-bit) before clamping. For large 'elapsed' values, this can overflow. The value should be clamped to the window size (or a safe max) using int64 arithmetic BEFORE converting to int.",
      "status": "completed",
      "completionDate": "2026-02-02T21:00:00+11:00",
      "critical": true,
      "dependsOn": [
        "RV09"
      ],
      "sourceDocument": "eventloop/review.md",
      "location": "eventloop/metrics.go",
      "deliverables": [
        "Perform clamping on int64/Duration result of division",
        "Cast to int only after ensuring value is within safe bounds (<= len(buckets))",
        "Prevent panic or overflow on extreme time jumps"
      ],
      "acceptanceCriteria": [
        "Safe execution on 32-bit architectures",
        "No overflow for large elapsed durations"
      ]
    },
    {
      "id": "RV11",
      "title": "Remove Unused totalCount Atomic",
      "description": "The 'totalCount' field is incremented but never read. It adds unnecessary overhead.",
      "status": "not-started",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/review.md",
      "location": "eventloop/metrics.go",
      "deliverables": [
        "Remove totalCount field from TPSCounter",
        "Remove totalCount.Add(1) from Increment()"
      ],
      "acceptanceCriteria": [
        "Struct is smaller",
        "No dead code remains"
      ]
    },
    {
      "id": "RV12",
      "title": "Fix TPS Calculation Sizing Mismatch",
      "description": "When windowSize is not a multiple of bucketSize, the TPS calculation divides by windowSize, but the actual monitored time is (len(buckets) * bucketSize). This causes systematic error. The divisor should be the actual monitored duration.",
      "status": "not-started",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/review.md",
      "location": "eventloop/metrics.go",
      "deliverables": [
        "Update TPS() calculation to divide by (float64(len(buckets)) * bucketSize.Seconds())",
        "Alternatively, enforce divisibility in constructor"
      ],
      "acceptanceCriteria": [
        "TPS calculation uses exact monitored duration",
        "No systematic under/over-reporting"
      ]
    },
    {
      "id": "T22",
      "title": "REACHING TRUE 100% COVERAGE",
      "description": "Achieve 100% effective test coverage for both eventloop and goja-eventloop packages, covering all code paths, error branches, edge cases, and platform-specific code. This includes comprehensive testing of all logic paths, concurrent scenarios, boundary conditions, and error propagation. Target: 100% line coverage, 100% branch coverage, and 100% function coverage across all variants and modules.",
      "status": "not-started",
      "critical": true,
      "dependsOn": [],
      "deliverables": [
        "Comprehensive test suite expansion for both eventloop and goja-eventloop",
        "Coverage analysis showing 100% across all metrics (line, branch, function)",
        "Tests for all error paths, edge cases, and concurrent scenarios",
        "Platform-specific code coverage verification",
        "Final coverage report with zero uncovered lines"
      ],
      "acceptanceCriteria": [
        "eventloop main coverage: 100%",
        "eventloop alternateone coverage: 100%",
        "eventloop alternatetwo coverage: 100%",
        "eventloop alternatethree coverage: 100%",
        "goja-eventloop main coverage: 100%",
        "All tests pass with -race flag (zero data races)",
        "No unreachable code paths remain uncovered",
        "Coverage report shows 100% across all metrics",
        "Comprehensive edge case and error path testing"
      ]
    },
    {
      "id": "T23",
      "title": "VALIDATING PERFORMANCE, ITERATING PERFORMANCE",
      "description": "Comprehensive performance validation and iterative optimization for both eventloop and goja-eventloop packages. This includes benchmark suites, performance profiling, memory analysis, throughput testing, and latency measurements across all variants and integration scenarios. Identify and implement performance optimizations, validate improvements through statistical analysis, and ensure no regressions are introduced.",
      "status": "not-started",
      "critical": true,
      "dependsOn": [
        "T22"
      ],
      "deliverables": [
        "Comprehensive benchmark suite for both packages",
        "Performance profiling and optimization analysis",
        "Memory usage and allocation analysis",
        "Throughput and latency measurements",
        "Statistical validation of performance improvements",
        "Performance regression detection and prevention",
        "Optimization documentation and rationale"
      ],
      "acceptanceCriteria": [
        "Benchmark results are reproducible and statistically significant",
        "Performance improvements quantified with before/after metrics",
        "No performance regressions detected",
        "Memory usage optimized (no leaks, efficient allocations)",
        "Throughput and latency targets met or exceeded",
        "All optimizations documented with rationale",
        "Performance characteristics stable across runs",
        "Integration performance validated across both packages"
      ]
    },
    {
      "id": "T6",
      "title": "Add comprehensive tests for JS integration error paths",
      "description": "Create comprehensive tests covering all uncovered error paths in js.go and ingress.go identified in coverage analysis. Focus on: (1) Ingress error conditions and double-check paths, (2) JS promise integration error handling, (3) Concurrent error scenarios, (4) Invalid input handling, (5) Error propagation through the event loop. These are the final critical coverage gaps needed to reach 90% coverage target.",
      "status": "in-progress",
      "critical": true,
      "deliverables": [
        "Test file: eventloop/js_integration_error_paths_test.go (10 tests completed)",
        "Document: COVERAGE_TEST_RECOMMENDATIONS.md (recommendations completed)",
        "Additional tests for remaining coverage gaps: microtask edge cases, chunked queue edge cases",
        "Coverage target: 84.7% \u2192 87-88% (90% may require architectural improvements)"
      ],
      "acceptanceCriteria": [
        "All new tests pass with -race flag",
        "Coverage increases from 84.7% to 87-88%",
        "Error paths in js.go and ingress.go are fully exercised",
        "Zero data races detected"
      ]
    },
    {
      "id": "SQL01",
      "title": "CRITICAL: SQL Export Buffer Pool Implementation \u26a1",
      "description": "Implement sync.Pool for row buffers in sql/export/export.go:184,186 to reduce allocations for large data exports. Current implementation allocates new buffers for each row export, causing 30-50% more allocations than necessary. Implementing a buffer pool will drastically reduce GC pressure and improve export performance.",
      "status": "not-started",
      "critical": true,
      "dependsOn": [],
      "sourceDocument": "improvements-roadmap.md #1",
      "expectedImpact": "30-50% reduction in allocations for large data exports",
      "deliverables": [
        "Implement sync.Pool for row buffers in sql/export/export.go",
        "Add buffer pool initialization",
        "Implement buffer reset before release back to pool",
        "Tests for buffer pool correctness",
        "Benchmarks before/after showing allocation reduction",
        "Documentation of buffer pool usage"
      ],
      "acceptanceCriteria": [
        "Buffer pool reduces allocations by 30-50% in benchmarks",
        "Buffers are properly reset before reuse",
        "No buffer leaks or pool exhaustion",
        "Memory usage reduces for large exports",
        "All tests pass",
        "No data races in pool operations"
      ]
    },
    {
      "id": "LOG01",
      "title": "CRITICAL: Eventloop Structured Logging Integration \ud83d\udcdd",
      "description": "Replace 9 log.Printf calls with structured logging in eventloop/loop.go, promises.go, and js.go to improve production debugging efficiency by 3-5x. Current logging uses unstructured log.Printf which lacks correlation IDs, context fields, and log levels. This is NOT a global logger - this is replacing existing printf-style logging with structured logging using correlation IDs, context fields, and proper log levels.",
      "status": "not-started",
      "critical": true,
      "dependsOn": [],
      "sourceDocument": "improvements-roadmap.md #3",
      "expectedImpact": "Production debugging efficiency 3-5x improvement",
      "deliverables": [
        "Design structured log message format",
        "Implement correlation ID generation (UUID)",
        "Add context fields (loop ID, task ID, timer ID)",
        "Replace log.Printf calls with structured logging",
        "Add log levels (debug, info, warn, error)",
        "Tests for structured logging behavior",
        "Documentation of log format and usage"
      ],
      "acceptanceCriteria": [
        "All log.Printf calls replaced with structured logging",
        "Correlation IDs track async operations across goroutines",
        "Context fields provide debugging context",
        "Log levels filter appropriately",
        "Production debugging is 3-5x more efficient",
        "No performance regression from structured logging",
        "All tests pass"
      ]
    },
    {
      "id": "R101",
      "title": "HIGH: Microtask Ring Buffer Sequence Zero Edge Case",
      "description": "The microtask ring buffer in eventloop/ring.go:291-302 uses seq == 0 as a sentinel value for 'empty slot' to distinguish between 'producer claimed slot but hasn't stored seq yet' and 'slot is actually empty'. Under extreme concurrent producer load or specific timing, it's possible for the seq value to legitimately be zero (wraps around from MAX_UINT64 = 2^64-1) while the slot contains valid data. The current implementation treats seq == 0 as always requiring a spin/retry, which could cause infinite spin if producer wraps sequence numbers repeatedly while data is valid.",
      "status": "not-started",
      "critical": true,
      "dependsOn": [],
      "sourceDocument": "EXHAUSTIVE_CODEBASE_REVIEW_2026-01-31.md",
      "location": "eventloop/ring.go:291-302",
      "impact": "Medium - improves robustness of microtask processing under extreme load. The current implementation works correctly in practice, but this edge case could theoretically occur.",
      "deliverables": [
        "Add explicit validity flag array to track valid slots",
        "Use atomic.Bool for validity tracking",
        "Update Push to mark valid explicitly after storing data",
        "Update Pop to check validity before processing",
        "Handle sequence wrap-around without ambiguity",
        "Tests for sequence wrap-around scenarios",
        "Tests for extreme concurrent producer load",
        "Stress tests for sequence number wrapping"
      ],
      "acceptanceCriteria": [
        "Validity flags correctly track slot state",
        "No ambiguity between 'empty' and 'not yet written'",
        "Sequence wrap-around handled correctly",
        "No infinite spin loops under wrap-around",
        "All tests pass",
        "No performance regression from validity checks"
      ]
    },
    {
      "id": "R103",
      "title": "HIGH: Limited Test Coverage for Iterator Protocol Errors",
      "description": "The iterator protocol in consumeIterable can throw errors (e.g., next() method not callable, returns non-object, throws during iteration). While these errors are handled by returning an error, there are NO tests verifying that: (1) The consuming promise properly rejects with the iterator error, (2) The error message is meaningful and helpful, (3) Multiple types of iterator errors are tested, (4) Malformed iterators (missing next(), next() returning non-object with done: true) are handled.",
      "status": "not-started",
      "critical": true,
      "dependsOn": [],
      "sourceDocument": "EXHAUSTIVE_CODEBASE_REVIEW_2026-01-31.md",
      "location": "goja-eventloop/test suite",
      "impact": "Medium - improves confidence in iterator protocol error handling and prevents edge case bugs in production.",
      "deliverables": [
        "Test file: goja-eventloop/adapter_iterator_error_test.go",
        "Test for next method not callable (TypeError)",
        "Test for next() throws during iteration",
        "Test for malformed iterator (next returns non-object with done: true)",
        "Test for infinite iterator respect consumption limits",
        "Test for mixed valid/invalid iterables in combinators",
        "Verify error messages are meaningful",
        "Verify promise rejection behavior"
      ],
      "acceptanceCriteria": [
        "All iterator error scenarios are tested",
        "Promises properly reject with iterator errors",
        "Error messages are meaningful and helpful",
        "Malformed iterators handled gracefully",
        "Combinators handle mixed iterator errors correctly",
        "All new tests pass",
        "Coverage increases"
      ]
    },
    {
      "id": "R130",
      "title": "Code Quality Fixes (Consolidated from R105-R110)",
      "description": "Consolidated initiative addressing multiple low-to-medium priority code quality issues: (1) R105: Redundant cache line padding comments in poller structures, (2) R106: Unnecessary atomic load comment clarification in ChunkedIngress, (3) R107: Inconsistent error handling for promise identity cycle detection (should reject, not fulfill), (4) R108: Documentation gaps in catrate limiter (NewLimiter requirements), (5) R109: Inefficient array indexing in consumeIterable using strconv.Itoa in loop, (6) R110: Duplicate code in gojaFuncToHandler type checking. All fixes improve maintainability, clarity, and spec compliance.",
      "status": "not-started",
      "critical": false,
      "dependsOn": [],
      "consolidatedFrom": [
        "R105",
        "R106",
        "R107",
        "R108",
        "R109",
        "R110"
      ],
      "subtasks": [
        {
          "id": "R130.1",
          "title": "Fix poller cache line padding comments",
          "description": "Remove or update misleading comments about cache line padding in poller_darwin.go, poller_linux.go, and poller_windows.go. Comments incorrectly state padding is needed after 4-byte int32 field when actual padding would be after 256-byte eventBuf field.",
          "location": [
            "eventloop/poller_darwin.go",
            "eventloop/poller_linux.go",
            "eventloop/poller_windows.go"
          ],
          "acceptanceCriteria": [
            "Comments accurately reflect field layout",
            "No misleading comments remain"
          ]
        },
        {
          "id": "R130.2",
          "title": "Clarify atomic load comment in ChunkedIngress",
          "description": "Update comment in ChunkedIngress.Pop() to clarify that chunkSize is a compile-time constant, not a variable loaded from global. The code is a micro-optimization but the comment is misleading.",
          "location": [
            "eventloop/ingress.go:133-156"
          ],
          "acceptanceCriteria": [
            "Comment accurately describes the code",
            "Code clarity improved"
          ]
        },
        {
          "id": "R130.3",
          "title": "Fix promise self-resolution error handling",
          "description": "Add early return after p.reject() call in promise identity cycle check. Currently code continues to fulfill promise after detection, violating Promise/A+ semantics. Self-resolution should reject with TypeError, not fulfill with error as value.",
          "location": [
            "eventloop/promise.go:341-348"
          ],
          "acceptanceCriteria": [
            "Self-resolution rejects with TypeError",
            "Promise is rejected not fulfilled",
            "Early return prevents continuing to fulfillment",
            "Promise/A+ compliance verified"
          ]
        },
        {
          "id": "R130.4",
          "title": "Document catrate limiter requirements",
          "description": "Add comprehensive documentation for NewLimiter including rate map requirements (keys, values, monotonicity), rate meaning (events per duration), behavior (Allow API, sliding window), example usage, and validation behavior. Remove TODO comment.",
          "location": [
            "catrate/limiter.go:32-39"
          ],
          "acceptanceCriteria": [
            "Rate map requirements clearly documented",
            "Example usage provided",
            "Validation logic explained",
            "TODO comment removed"
          ]
        },
        {
          "id": "R130.5",
          "title": "Optimize array indexing in consumeIterable",
          "description": "Replace inefficient string conversion (strconv.Itoa in loop) in array fast path with Go slice operations or cached string conversion. Investigate goja.Value.ToArray() availability or optimize current approach.",
          "location": [
            "goja-eventloop/adapter.go:243-262"
          ],
          "acceptanceCriteria": [
            "Array conversion is faster",
            "No behavior changes",
            "All tests pass",
            "Benchmarks show improvement"
          ]
        },
        {
          "id": "R130.6",
          "title": "Refactor duplicate type checking code",
          "description": "Extract repeated promise type checking (*goja.Object) in gojaFuncToHandler into helper function. Type checking appears twice (top of function and in loop). Reuse helper in both locations to DRY up code.",
          "location": [
            "goja-eventloop/adapter.go:410-447"
          ],
          "acceptanceCriteria": [
            "No duplicate type checking code",
            "Helper function well-named and clear",
            "All code paths work correctly",
            "No behavior changes"
          ]
        }
      ],
      "deliverables": [
        "All poller padding comments fixed or clarified",
        "ChunkedIngress atomic load comment clarified",
        "Promise self-resolution error handling fixed",
        "Catrate limiter documentation completed",
        "Array indexing optimization implemented",
        "Duplicate type checking refactored",
        "Tests for all fixes",
        "No behavior changes or regressions"
      ],
      "acceptanceCriteria": [
        "All 6 subtasks completed",
        "Code clarity and maintainability improved",
        "Promise/A+ compliance verified",
        "Documentation gaps filled",
        "All tests pass",
        "No performance regressions"
      ]
    },
    {
      "id": "R131",
      "title": "Resolve All TODO/FIXME/HACK Markers (Consolidated from T91)",
      "description": "Resolve all 23 code markers (TODO: 18, FIXME: 3, HACK: 2) across eventloop/, goja-eventloop/, and catrate/ modules. Markers span categories: test failures/timing issues (multiple fastpath tests), architectural improvements (microtask queue, poller), feature enhancements (JS API, metrics), and documentation/refactoring. Each marker must be either resolved (fixed/implemented) or formally deferred with documented rationale.",
      "status": "not-started",
      "critical": false,
      "dependsOn": [],
      "consolidatedFrom": [
        "T91"
      ],
      "markerSummary": {
        "totalMarkers": 23,
        "byModule": {
          "eventloop/": 15,
          "goja-eventloop/": 5,
          "catrate/": 3
        },
        "byType": {
          "TODO": 18,
          "FIXME": 3,
          "HACK": 2
        }
      },
      "deliverables": [
        "All test failure and timing issue markers resolved",
        "All architectural improvement markers addressed or formally deferred",
        "Resolution plan for feature enhancement markers",
        "Documentation updates for resolved markers",
        "Tracking document for marker lifecycle",
        "Zero unresolved critical markers"
      ],
      "acceptanceCriteria": [
        "Zero critical TODO/FIXME markers remain",
        "All resolutions documented with rationale",
        "No new markers introduced",
        "Documentation reflects final state",
        "All marker resolutions reviewed"
      ]
    },
    {
      "id": "R132",
      "title": "Enhancements (Consolidated from T62-T64, T66-T71, excluding T65)",
      "description": "Consolidated initiative for enhancement and improvement tasks across the codebase (9 tasks: T62, T63, T64, T66, T67, T68, T69, T70, T71). These tasks represent feature requests, performance optimizations, and architectural improvements that enhance the library's capabilities, usability, and maintainability. Tasks include API improvements, additional testing, documentation enhancements, and minor feature additions.",
      "status": "not-started",
      "critical": false,
      "dependsOn": [],
      "consolidatedFrom": [
        "T62",
        "T63",
        "T64",
        "T66",
        "T67",
        "T68",
        "T69",
        "T70",
        "T71"
      ],
      "deliverables": [
        "Enhanced API with better ergonomics",
        "Comprehensive test additions",
        "Performance optimizations implemented",
        "Improved documentation",
        "Refactored and cleaner code",
        "All enhancements tested"
      ],
      "acceptanceCriteria": [
        "All 9 source tasks (T62-T64, T66-T71) addressed appropriately",
        "API is more user-friendly",
        "Test coverage improved",
        "Performance better or maintained",
        "Documentation comprehensive",
        "Code quality improved",
        "All tests pass"
      ]
    }
  ],
  "continuousVerification": {
    "task": "Run 'make all' with full logging after EVERY significant change",
    "description": "Execute 'make all 2>&1 | fold -w 200 | tee build.log | tail -n 15' after: (a) Each code change, (b) Each test addition, (c) Each task completion, (d) Each bug fix, (e) Each review cycle. This is a CONTINUOUS task that must be executed throughout the entire plan without exception.",
    "failPolicy": "If ANY test fails, STOP IMMEDIATELY and fix the issue before proceeding. Zero tolerance for test failures, timing issues, non-determinism, or race conditions. Do not skip, defer, or ignore any test failure."
  }
}