{
  "policy": "ALL tasks and subtasks contained within this blueprint MUST be completed in their entirety. Deferring, skipping, or omitting any part of the plan is strictly prohibited. Every unit defined here represents a mandatory component of final delivery. 'Effective test coverage' means covering ALL code paths, edge cases, and error conditions - not just line coverage. This includes unreachable paths, error branches, and platform-specific code.",
  "coverageDefinition": {
    "effectiveCoverage": "Coverage of all logic paths, error branches, edge cases, and platform-specific code. Must handle null/undefined inputs, error propagation, concurrent access, and boundary conditions.",
    "targetMetrics": {
      "minimumLineCoverage": "100% of all possible code paths",
      "minimumBranchCoverage": "100% of all possible code paths",
      "minimumFunctionCoverage": "100% of all possible code paths",
      "errorPathCoverage": "100% not inclusive of TRULY unreachable code i.e. invariant assertions"
    }
  },
  "tasks": [
    {
      "id": "T25",
      "title": "CRITICAL: Remove global logger and use logiface.L instead",
      "description": "COMPLETELY REPLACING the egregious logging.go implementation violation. The current logging.go implementation is WRONG on multiple levels: (1) Uses global logger variable (BANNED), (2) Implements custom logger in eventloop module when github.com/joeycumines/logiface EXISTS IN THE WORKSPACE, (3) Violates proper dependency injection patterns. The eventloop module should NOT implement logging - it should DEPEND on logiface.L for logging services via proper configuration/option passing. Remove eventloop/logging.go entirely and replace with proper logiface.L usage throughout eventloop codebase. Logger should be passed via LoopOptions or similar configuration mechanism, NOT as global state.",
      "status": "not-started",
      "priority": "P0",
      "critical": true,
      "dependsOn": [],
      "deliverables": [
        "Complete removal of eventloop/logging.go (the entire file - all 684 lines)",
        "Complete removal of eventloop/logging_test.go (all 454 lines)",
        "Identification of all code in eventloop/ that uses the logging.go functions",
        "Design document for proper logiface.L integration via dependency injection",
        "Updated LoopOptions (or equivalent) to accept logiface.L logger instance",
        "Search and replace: all SDebug/SInfo/SWarn/SErr calls replaced with logiface.L-based logger calls",
        "Verification: NO global logger variables remain in eventloop/",
        "Verification: ALL logging goes through logiface.L only",
        "Documentation updates explaining the proper logging pattern"
      ],
      "acceptanceCriteria": [
        "eventloop/logging.go is COMPLETELY DELETED",
        "eventloop/logging_test.go is COMPLETELY DELETED",
        "NO global logger variables exist in eventloop/",
        "The *logiface.Logger value is passed in and used directly - a nil value (pointer, default) is a no-op logger. It may be necessary to add fast-path checks based on the logiface.Logger.Enabled()",
        "ALL logging in eventloop/ uses logiface.L (import github.com/joeycumines/logiface)",
        "Logger instances are passed via configuration/dependencies, NOT globals",
        "All existing tests still pass (100% pass rate)",
        "-race detector shows zero data races",
        "Code follows proper dependency injection patterns",
        "Documentation clearly explains the correct logging approach",
        "T19 (logging implementation) is marked as OVERTURNED/REJECTED in blueprint history"
      ],
      "overrides": {
        "overtasks": [
          "T19"
        ],
        "reason": "T19 implemented a global logger and custom logging implementation in violation of project standards. The correct approach is to use the existing logiface.L in the workspace via dependency injection, not to reimplement logging."
      }
    },
    {
      "id": "T22",
      "title": "REACHING TRUE 100% COVERAGE",
      "description": "Achieve 100% effective test coverage for both eventloop and goja-eventloop packages, covering all code paths, error branches, edge cases, and platform-specific code. This includes comprehensive testing of all logic paths, concurrent scenarios, boundary conditions, and error propagation. Target: 100% line coverage, 100% branch coverage, and 100% function coverage across all variants and modules.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T21"
      ],
      "deliverables": [
        "Comprehensive test suite expansion for both eventloop and goja-eventloop",
        "Coverage analysis showing 100% across all metrics (line, branch, function)",
        "Tests for all error paths, edge cases, and concurrent scenarios",
        "Platform-specific code coverage verification",
        "Final coverage report with zero uncovered lines"
      ],
      "acceptanceCriteria": [
        "eventloop main coverage: 100%",
        "eventloop alternateone coverage: 100%",
        "eventloop alternatetwo coverage: 100%",
        "eventloop alternatethree coverage: 100%",
        "goja-eventloop main coverage: 100%",
        "All tests pass with -race flag (zero data races)",
        "No unreachable code paths remain uncovered",
        "Coverage report shows 100% across all metrics",
        "Comprehensive edge case and error path testing"
      ]
    },
    {
      "id": "T23",
      "title": "VALIDATING PERFORMANCE, ITERATING PERFORMANCE",
      "description": "Comprehensive performance validation and iterative optimization for both eventloop and goja-eventloop packages. This includes benchmark suites, performance profiling, memory analysis, throughput testing, and latency measurements across all variants and integration scenarios. Identify and implement performance optimizations, validate improvements through statistical analysis, and ensure no regressions are introduced.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T22"
      ],
      "deliverables": [
        "Comprehensive benchmark suite for both packages",
        "Performance profiling and optimization analysis",
        "Memory usage and allocation analysis",
        "Throughput and latency measurements",
        "Statistical validation of performance improvements",
        "Performance regression detection and prevention",
        "Optimization documentation and rationale"
      ],
      "acceptanceCriteria": [
        "Benchmark results are reproducible and statistically significant",
        "Performance improvements quantified with before/after metrics",
        "No performance regressions detected",
        "Memory usage optimized (no leaks, efficient allocations)",
        "Throughput and latency targets met or exceeded",
        "All optimizations documented with rationale",
        "Performance characteristics stable across runs",
        "Integration performance validated across both packages"
      ]
    },
    {
      "id": "T6",
      "title": "Add comprehensive tests for JS integration error paths",
      "description": "Create comprehensive tests covering all uncovered error paths in js.go and ingress.go identified in coverage analysis. Focus on: (1) Ingress error conditions and double-check paths, (2) JS promise integration error handling, (3) Concurrent error scenarios, (4) Invalid input handling, (5) Error propagation through the event loop. These are the final critical coverage gaps needed to reach 90% coverage target.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "deliverables": [
        "Test file: eventloop/js_integration_error_paths_test.go (20+ tests)",
        "Test file: eventloop/ingress_error_paths_test.go (15+ tests)",
        "Comprehensive coverage of all previously uncovered error paths",
        "Zero data races detected with -race flag",
        "All new tests integrated into test suite with proper documentation"
      ],
      "acceptanceCriteria": [
        "All new tests pass",
        "Coverage analysis shows significant reduction in uncovered lines (target: <10% uncovered)",
        "No data races detected (-race clean)",
        "Main eventloop coverage increases from 84.6% to target 90%+",
        "Error paths in js.go and ingress.go are fully exercised"
      ]
    },
    {
      "id": "T7",
      "title": "Complete eventloop module to 90%+ coverage",
      "description": "Run final comprehensive coverage analysis for the entire eventloop module and add any necessary additional tests to reach the target metrics: main >= 90%, alternateone >= 90%, alternatethree >= 85%, alternatetwo >= 90%. Verify that all code paths, error branches, edge cases, and platform-specific code are covered. Add tests for any remaining gaps identified.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T6"
      ],
      "deliverables": [
        "Final coverage profile: go test -coverprofile=coverage.out ./eventloop/... && go tool cover -html=coverage.out -o coverage.html",
        "Coverage analysis document with metrics per package and variant",
        "Any additional test files for remaining coverage gaps (if any)",
        "Verification that all target metrics are achieved",
        "Coverage report uploaded and made available for review"
      ],
      "acceptanceCriteria": [
        "main coverage >= 90%",
        "alternateone coverage >= 90%",
        "alternatethree coverage >= 85% (experimental)",
        "alternatetwo coverage >= 90%",
        "All tests pass with -race flag",
        "No unreachable critical code paths remain uncovered",
        "Coverage report clearly shows all covered and uncovered lines"
      ]
    },
    {
      "id": "T8",
      "title": "Add critical path tests for goja-eventloop adapter",
      "description": "Create comprehensive tests for the goja-eventloop adapter core functions (exportGojaValue, gojaFuncToHandler, resolveThenable, convertToGojaValue) covering all critical error paths, edge cases, and null/undefined handling identified in coverage analysis. This is Phase 1 of goja-eventloop coverage improvement targeting the highest-impact gaps.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "deliverables": [
        "Test file: goja-eventloop/adapter_critical_paths_test.go (~21 tests)",
        "Comprehensive coverage of exportGojaValue (critical: 42.9% -> 100%)",
        "Comprehensive coverage of gojaFuncToHandler (critical: 68.4% -> 100%)",
        "Comprehensive coverage of resolveThenable (critical: 61.8% -> 100%)",
        "Comprehensive coverage of convertToGojaValue (critical: 72.4% -> 100%)",
        "Zero data races detected"
      ],
      "acceptanceCriteria": [
        "All new tests pass",
        "Coverage analysis shows significant improvement in all 4 target functions",
        "No data races detected with -race flag",
        "goja-eventloop coverage increases from 74.0% toward 90% target"
      ]
    },
    {
      "id": "T9",
      "title": "Add combinator edge case tests for goja-eventloop",
      "description": "Create comprehensive edge case tests for Promise combinators (Promise.all, Promise.race, Promise.allSettled, Promise.any) focusing on: null/undefined inputs, array edge cases, empty arrays, mixed resolution/rejection scenarios, and deeply nested promises. This is Phase 2 of goja-eventloop coverage improvement.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T8"
      ],
      "deliverables": [
        "Test file: goja-eventloop/adapter_combinators_edge_cases_test.go (~12 tests)",
        "Coverage of all combinator edge cases and error conditions",
        "Zero data races detected",
        "Clear documentation of test scenarios and expected behaviors"
      ],
      "acceptanceCriteria": [
        "All new tests pass",
        "Coverage analysis shows improvement in combinator functions",
        "No regressions in existing tests",
        "All edge cases tested: null, undefined, empty, large arrays, mixed states"
      ]
    },
    {
      "id": "T10",
      "title": "Add timer edge case tests for goja-eventloop",
      "description": "Create comprehensive timer ID boundary tests for goja-eventloop focusing on: MAX_SAFE_INTEGER limits, overflow scenarios, ID reuse edge cases, concurrent timer scheduling with high IDs, and timer cleanup scenarios. This is Phase 3 of goja-eventloop coverage improvement.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T9"
      ],
      "deliverables": [
        "Test file: goja-eventloop/adapter_timer_edge_cases_test.go (~16 tests)",
        "Coverage of all timer ID boundary conditions and concurrent scenarios",
        "Zero data races detected",
        "Documentation of timer ID allocation strategy and limits"
      ],
      "acceptanceCriteria": [
        "All new tests pass",
        "Coverage analysis shows improvement in timer-related functions",
        "No regressions in existing tests",
        "Edge cases tested: overflow, reuse, concurrency, cleanup, boundary values"
      ]
    },
    {
      "id": "T11",
      "title": "Complete goja-eventloop module to 90%+ coverage",
      "description": "Run final comprehensive coverage analysis for the goja-eventloop module and add any necessary additional tests to reach the target metric: main >= 90%. Verify that all code paths, error branches, edge cases, and timer logic are covered. Ensure coverage targets are met and all functionality is tested.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T10"
      ],
      "deliverables": [
        "Final coverage profile: go test -coverprofile=coverage.out ./goja-eventloop/... && go tool cover -html=coverage.out -o coverage.html",
        "Coverage analysis document identifying any remaining gaps",
        "Any additional test files for remaining coverage gaps (if any)",
        "Verification that 90% target metric is achieved",
        "Final coverage report with per-function breakdown"
      ],
      "acceptanceCriteria": [
        "goja-eventloop main coverage >= 90%",
        "All tests pass with -race flag",
        "No unreachable critical code paths remain uncovered",
        "Coverage analysis report documents all paths covered",
        "Coverage is evenly distributed across all functions (no zero-coverage functions remain)"
      ]
    },
    {
      "id": "T12",
      "title": "Re-verify Goja-Eventloop Integration against main branch",
      "description": "Comprehensive re-verification review of the Goja-Eventloop Integration (LOGICAL_CHUNK_1) against the current main branch to ensure no regressions from eventloop core changes and Main promise refactoring in T1-T5. This is a MAXIMUM PARANOIA review following the established pattern from previous review cycles.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T5",
        "T11"
      ],
      "deliverables": [
        "Comprehensive review document: ./goja-eventloop/docs/reviews/41-LOGICAL1_REVERIFICATION.md",
        "Detailed analysis of all changes vs main branch",
        "Succinct summary (must be optimal, removing any part would degrade)",
        "Detailed findings with specific line references and issue identification",
        "Actionable fix recommendations for any issues found"
      ],
      "acceptanceCriteria": [
        "Review is thorough and questions ALL information (MAXIMUM PARANOIA)",
        "Only trusts information that is impossible to verify",
        "Review follows strict format requirements (succinct summary + detailed analysis)",
        "Findings are actionable and well-documented with specific code references",
        "No critical issues remain unidentified",
        "Assessment of risk and confidence is clearly stated"
      ]
    },
    {
      "id": "T13",
      "title": "Fix all issues found in Goja-Eventloop re-verification",
      "description": "Address ALL issues found in T12 re-verification review comprehensively. This includes: fixing any bugs, addressing any race conditions, optimizing any performance issues, handling any edge cases, and resolving any API inconsistencies. Use runSubagent or direct implementation as appropriate. Every single issue must be resolved before proceeding.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T12"
      ],
      "deliverables": [
        "All identified issues fixed comprehensively with root cause resolution",
        "All affected tests updated or added (regression tests)",
        "All fixes verify with -race detector (zero data races)",
        "Documentation updated as necessary (comments, docs, changelogs)",
        "Verification that no new issues are introduced by fixes"
      ],
      "acceptanceCriteria": [
        "All tests pass including new regression tests for each fix",
        "Zero data races detected across entire goja-eventloop module",
        "No new issues introduced by the fixes (no regressions)",
        "All original issues identified in T12 are resolved",
        "Fixes are minimal and targeted (avoid over-engineering)",
        "Code review confirms fixes address root causes not symptoms"
      ]
    },
    {
      "id": "T14",
      "title": "Verify Goja-Eventloop to perfection",
      "description": "Re-review the Goja-Eventloop Integration after T13 fixes ensuring UTTER PERFECTION is achieved. If ANY issues remain, restart the T12, T13, T14 cycle (review, fix, re-verify) until the verdict is PERFECT with zero remaining issues. This cycle continues until the module is verified to be production-ready with absolutely no outstanding concerns.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T13"
      ],
      "deliverables": [
        "Perfection review document: ./goja-eventloop/docs/reviews/42-LOGICAL1_PERFECTION.md",
        "Final verdict: PERFECT or continuation of review-fix-reverify cycle",
        "Documentation of all review cycle iterations if multiple passes needed",
        "Final assessment of production readiness"
      ],
      "acceptanceCriteria": [
        "Verdict is PERFECT with no remaining issues",
        "MAXIMUM PARANOIA review shows zero concerns",
        "No regressions introduced in any iteration",
        "Review document satisfies all format requirements",
        "Confidence assessment: PRODUCTION READY",
        "All review cycles from previous work remain valid (no new issues introduced)"
      ]
    },
    {
      "id": "T15",
      "title": "Final comprehensive cross-module integration testing",
      "description": "Run comprehensive integration tests across both eventloop and goja-eventloop modules to ensure all optimizations, refactoring, and coverage improvements work together correctly. This includes: cross-module scenario tests, full-stack integration tests, tournament competition across all variants, and stress testing of the complete system. This is the final validation before production readiness.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T7",
        "T11",
        "T14"
      ],
      "deliverables": [
        "Cross-module integration test results (all tests pass)",
        "Performance analysis across both modules showing no regressions",
        "Tournament results with all optimizations applied (all 5 variants compete)",
        "Final production readiness assessment with risk analysis",
        "Integration test coverage report"
      ],
      "acceptanceCriteria": [
        "All cross-module integration tests pass",
        "No regressions in either module (eventloop or goja-eventloop)",
        "Performance improvements verified across both modules",
        "Zero data races detected in comprehensive testing (-race clean)",
        "Both modules meet 90%+ coverage targets",
        "Tournament competition shows fair results across all variants",
        "Stress tests show no failures or unexpected behavior"
      ]
    },
    {
      "id": "T16",
      "title": "Final benchmark validation and documentation",
      "description": "Run a final comprehensive benchmark suite to quantify all performance improvements, document all optimizations made, and create final production-ready documentation for both modules. This includes before/after comparisons, optimization rationales, performance characteristics of all variants, user-facing documentation updates, and clear documentation of any trade-offs made.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T15"
      ],
      "deliverables": [
        "Comprehensive benchmark report comparing before/after for all variants",
        "Optimization documentation for Main promise migration (T4)",
        "Performance characteristics document for all tournament variants",
        "Production readiness summary with clear recommendations",
        "User-facing documentation updates (README, migration guides, API docs)",
        "Architecture decision records (ADRs) for major changes"
      ],
      "acceptanceCriteria": [
        "Benchmark results are reproducible across 10+ runs",
        "Documentation is clear, actionable, and technically accurate",
        "All performance improvements are quantified with statistical significance",
        "Production readiness is clearly justified with evidence",
        "User documentation reflects all API changes and improvements",
        "Trade-offs and design decisions are well-documented"
      ]
    },
    {
      "id": "T17",
      "title": "Final comprehensive verification and production sign-off",
      "description": "Run the final comprehensive verification suite on both macOS and linux-container platforms to ensure everything builds, passes tests, passes vet, staticcheck, betteralign, and that all 200+ tests pass with zero failures across both eventloop and goja-eventloop modules. This is the final gate before declaring the feature branch production-ready for merge.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T16"
      ],
      "deliverables": [
        "Complete build logs for macOS and linux: make all 2>&1 | fold -w 200 | tee build.log | tail -n 15",
        "Test results across all modules and variants (200+ tests, 100% pass rate)",
        "Platform-specific validation results (both platforms pass)",
        "Final production readiness sign-off document",
        "Merge readiness checklist verification"
      ],
      "acceptanceCriteria": [
        "All packages build successfully on both platforms (no errors, no warnings)",
        "All tests pass: 200+ tests with 100% pass rate (zero failures)",
        "Zero data races detected across all tests (-race clean)",
        "No staticcheck warnings or errors",
        "No betteralign issues or alignment warnings",
        "Zero test failures or flaky tests across all platforms",
        "Both eventloop and goja-eventloop meet 90%+ coverage targets",
        "All 5 tournament variants compete successfully",
        "Production readiness sign-off checklist is complete with no blockers"
      ]
    },
    {
      "id": "T19",
      "title": "[OVERTURNED/REJECTED] Structured Logging Implementation",
      "description": "OVERTURNED BY T25. This task implemented a global logger and custom logging implementation in violation of project standards. The correct approach is to use the existing github.com/joeycumines/logiface package in the workspace via dependency injection, not to reimplement logging. The deliverables created in this task violate the core design principle: NO GLOBAL VARIABLES. See T25 for the correct implementation.",
      "status": "rejected",
      "priority": "P0",
      "critical": true,
      "dependsOn": [],
      "rejectedBy": "T25",
      "rejectionReason": "This task violated three critical design principles: (1) GLOBAL LOGGER IS BANNED - cannot use package-level logger variables, (2) REINVENTING THE WHEEL - eventloop implemented custom logging when github.com/joeycumines/logiface EXISTS IN THE WORKSPACE, (3) VIOLATION OF DEPENDENCY INJECTION - logger should be passed via configuration, not accessed globally. The entire T19 deliverable set (logging.go and logging_test.go) must be DELETED.",
      "overturnedInFavorOf": "T25",
      "completionTime": "2026-01-29T00:00:00Z",
      "implementationDetails": "684-line logging.go with 454-line test suite, 21 tests passing, full Logger interface, level filtering, lazy evaluation, package-level functions, functional options, domain-specific helpers, thread-safe - ALL VIOLATE DESIGN PRINCIPLES",
      "testResults": "21 tests PASSED in 0.570s, verified: Logger interface (DefaultLogger, WriterLogger, NoOpLogger, FileLogger), level filtering, lazy evaluation, package-level functions, functional options, domain-specific helpers, thread safety, JSON escaping, context integration - ALL MUST BE REMOVED",
      "deliverables": [
        "[DELETE] eventloop/logging.go (684 lines) - violated global logger ban",
        "[DELETE] eventloop/logging_test.go (454 lines) - violated global logger ban",
        "[REPLACE WITH] logiface.L integration via dependency injection",
        "[REPLACE WITH] Updated LoopOptions to accept logiface.L logger instance",
        "[REPLACE WITH] All logging converted to use logiface.L methods"
      ],
      "acceptanceCriteria": [
        "T19 acceptance criteria are REJECTED - this task was fundamentally flawed",
        "eventloop/logging.go MUST be DELETED",
        "eventloop/logging_test.go MUST be DELETED",
        "See T25 acceptance criteria for the correct implementation"
      ]
    },
    {
      "id": "T21",
      "title": "Integration Test Expansion (27 ‚Üí 50+ tests)",
      "description": "Expand the integration test suite beyond the existing 27 JS integration tests. Add cross-module integration tests for eventloop + goja-eventloop interaction. Target 50+ comprehensive integration tests covering all major interaction patterns between modules.",
      "status": "not-started",
      "priority": "P1",
      "critical": true,
      "dependsOn": [
        "T19"
      ],
      "deliverables": [
        "23+ new integration tests (expanding from 27 to 50+)",
        "Cross-module integration tests for eventloop + goja-eventloop",
        "Comprehensive coverage of major interaction patterns",
        "Zero data races detected with -race flag",
        "Documentation of integration test scenarios"
      ],
      "acceptanceCriteria": [
        "50+ total integration tests (27 existing + 23+ new)",
        "All integration tests pass with zero failures",
        "Cross-module interaction patterns fully tested",
        "Zero data races detected with -race flag",
        "Tests are deterministic and repeatable",
        "Code is production-ready with proper error handling"
      ]
    },
    {
      "id": "T28",
      "title": "Fix Close() immediate return deadlock",
      "description": "Close() must block until loop goroutine exits via loopDone channel to prevent race conditions and ensure clean shutdown.",
      "status": "not-started",
      "priority": "P0",
      "critical": true,
      "dependsOn": [],
      "deliverables": [
        "Fix Close() implementation to block on loopDone channel",
        "Add tests verifying proper shutdown sequence",
        "Verify no race conditions with -race flag"
      ],
      "acceptanceCriteria": [
        "Close() blocks until loop goroutine exits",
        "No data races detected",
        "All tests pass"
      ]
    },
    {
      "id": "T61",
      "title": "Quick Wins - Cross-Module Integration Test Expansion üß™",
      "description": "Expand from 27 tests to 50+ tests covering all boundary interactions between eventloop and goja-eventloop modules. Production bugs frequently emerge at module boundaries where single-module tests cannot detect them. Current tests are module-scoped only.",
      "status": "not-started",
      "priority": "P0",
      "critical": false,
      "dependsOn": [
        "T25"
      ],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #2 Cross-Module Integration Test Expansion",
      "expectedImpact": "Prevention of integration regressions, full-stack validation",
      "deliverables": [
        "23+ new integration tests (expanding from 27 to 50+)",
        "Cross-module integration tests for eventloop + goja-eventloop",
        "Tests covering Promise chains spanning Goja‚ÜíNative‚ÜíGoja boundaries with incorrect GC behavior",
        "Tests for Timer cancellation behavior conflicts between eventloop and goja-eventloop adapters",
        "Tests for Memory leaks arising from interaction between weak reference registry and Goja value caching",
        "Tests for State desynchronization bugs only visible in end-to-end scenarios",
        "Tests for Deeply nested promises (>10 levels) with mixed module sources",
        "Zero data races detected with -race flag",
        "Documentation of integration test scenarios"
      ],
      "acceptanceCriteria": [
        "50+ total integration tests (27 existing + 23+ new)",
        "All integration tests pass with zero failures",
        "Cross-module interaction patterns fully tested",
        "Zero data races detected with -race flag",
        "Tests are deterministic and repeatable",
        "Code is production-ready with proper error handling"
      ]
    },
    {
      "id": "T62",
      "title": "Enhancement - Eventloop Metrics Export Integration üìä",
      "description": "Add hooks for automated metrics export from eventloop/metrics.go including Prometheus metrics export (/metrics endpoint), OpenTelemetry integration (spans, metrics), and Custom metrics callbacks (user-defined aggregators). Current metrics are accessible via loop.Metrics() but must be manually sampled which is insufficient for production monitoring.",
      "status": "not-started",
      "priority": "P1",
      "critical": false,
      "dependsOn": [
        "T25"
      ],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #4 Eventloop Metrics Export Integration",
      "expectedImpact": "Production monitoring enablement, performance anomaly detection",
      "deliverables": [
        "Design and implement MetricsExporter interface",
        "Implement WithMetricsExporter LoopOption",
        "Prometheus exporter implementation",
        "OpenTelemetry integration",
        "Custom metrics callback implementation",
        "Tests for all exporters",
        "Documentation and examples"
      ],
      "acceptanceCriteria": [
        "MetricsExporter interface is clean and extensible",
        "Prometheus exporter outputs correct metrics format",
        "OpenTelemetry integration works correctly",
        "Custom callbacks work as expected",
        "Performance overhead is minimal",
        "All exporters are properly tested"
      ]
    },
    {
      "id": "T63",
      "title": "Enhancement - Goja-Eventloop Adapter Timeout Protection üõ°",
      "description": "Add per-operation timeout configuration to goja-eventloop/adapter.go to prevent JavaScript infinite loops blocking runtime, malicious scripts causing resource exhaustion, and Promise chains that never settle (circular dependencies). Current implementation has no timeout guard at adapter level. setTimeout, setInterval have no per-operation deadline enforcement.",
      "status": "not-started",
      "priority": "P1",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #5 Goja-Eventloop Adapter Timeout Protection",
      "expectedImpact": "Production resilience against malicious/degenerate user code",
      "deliverables": [
        "Design TimeoutConfig struct (DefaultTimeout, MaxExecutionTime, OnTimeout)",
        "Implement WithAdapterTimeout AdapterOption",
        "Add timeout enforcement for setTimeout",
        "Add timeout enforcement for setInterval",
        "Add timeout enforcement for async operations",
        "Tests for timeout behavior",
        "Tests for malicious code protection",
        "Documentation of timeout behavior"
      ],
      "acceptanceCriteria": [
        "TimeoutConfig correctly enforces per-operation deadlines",
        "Infinite loops are terminated within MaxExecutionTime",
        "OnTimeout callback is triggered correctly",
        "No performance overhead for well-behaved code",
        "All timeout tests pass",
        "Malicious scripts are safely terminated"
      ]
    },
    {
      "id": "T64",
      "title": "Enhancement - Batch Execution Timeout Policies ‚è±Ô∏è",
      "description": "Add timeout for batch executions in eventloop/loop.go to prevent runaway batch processing. Individual task timeouts (via ScheduleTimer) do NOT prevent batch starvation. If 100K tasks are queued and each takes 1ms, batch runs for 100 seconds blocking all timer operations. Currently there is no timeout for batch executions.",
      "status": "not-started",
      "priority": "P1",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #6 Batch Execution Timeout Policies",
      "expectedImpact": "Production resilience against runaway batch processing",
      "deliverables": [
        "Design BatchConfig struct (MaxExecutionTime, MaxTasksPerBatch, OnExceeded)",
        "Implement WithBatchTimeout LoopOption",
        "Add batch execution timeout enforcement",
        "Add batch task count limit enforcement",
        "Add OnExceeded callback handling",
        "Tests for batch timeout behavior",
        "Tests for batch task limit behavior",
        "Performance tests showing no overhead for normal batches"
      ],
      "acceptanceCriteria": [
        "Batch timeouts prevent runaway batches",
        "MaxTasksPerBatch prevents task starvation",
        "OnExceeded callback is triggered appropriately",
        "Normal batches have no performance overhead",
        "All batch timeout tests pass",
        "Cascading failures are prevented"
      ]
    },
    {
      "id": "T65",
      "title": "Enhancement - Promise Combinator Error Aggregation Test Coverage üß™",
      "description": "Add comprehensive test coverage for Promise combinators (lines 793-1076 in eventloop/promise.go) focusing on extreme scenarios. Current tests focus on happy paths with coverage gaps for extreme scenarios. Expected to close coverage gap by +2-3% and increase production confidence in edge cases.",
      "status": "not-started",
      "priority": "P1",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #7 Promise Combinator Error Aggregation Test Coverage",
      "expectedImpact": "Coverage gap closure (+2-3%), production confidence in edge cases",
      "deliverables": [
        "Test file: eventloop/promise_combinator_edge_cases_test.go",
        "Tests for deeply nested combinators (10+ levels)",
        "Tests for mixed resolution/rejection scenarios in large arrays (>1000 promises)",
        "Tests for error type preservation across combinator chains",
        "Tests for AggregateError structure validation for all rejection patterns",
        "Performance tests for large promise arrays",
        "Documentation of edge case behaviors"
      ],
      "acceptanceCriteria": [
        "All new tests pass",
        "Coverage increases by 2-3%",
        "Deep nesting scenarios correctly handled",
        "Large arrays (+1000 promises) work correctly",
        "Error type preservation verified",
        "AggregateError structures validated",
        "No performance regressions for normal use"
      ]
    },
    {
      "id": "T66",
      "title": "Enhancement - Microtask Overflow Buffer Compaction Test üì•",
      "description": "Add performance-validated tests for microtask overflow buffer compaction behavior in eventloop/ring.go and eventloop/ingress.go. Current overflow behavior under extreme load is tested but not performance-validated. Needed to understand performance envelope and validate optimization.",
      "status": "not-started",
      "priority": "P1",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #8 Microtask Overflow Buffer Compaction Test",
      "expectedImpact": "Understanding of performance envelope, optimization validation",
      "deliverables": [
        "Test file: eventloop/microtask_overflow_performance_test.go",
        "Tests for microtask flood scenarios (>10000 microtasks queued)",
        "Performance measurements for compaction overhead",
        "Analysis of copy vs allocation trade-off",
        "Tests for overflow-to-compacted state transition validation",
        "Benchmark suite for buffer sizing scenarios",
        "Documentation of performance characteristics"
      ],
      "acceptanceCriteria": [
        "All new tests pass",
        "Microtask flood scenarios correctly handled",
        "Compaction overhead is measured and documented",
        "Optimal buffer sizing parameters identified",
        "State transitions work correctly",
        "Performance benchmarks provide actionable data",
        "No memory leaks or unbounded growth"
      ]
    },
    {
      "id": "T67",
      "title": "Improvement - Error Context Structured Unwrapping üîç",
      "description": "Create structured error types with error codes, context maps, unwrapping, and hints for retry logic in eventloop/loop.go (lines 8-27). This improves production error handling clarity by 5-10x.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #9 Error Context Structured Unwrapping",
      "expectedImpact": "Production error handling clarity 5-10x improvement",
      "deliverables": [
        "Design structured error type hierarchy",
        "Implement error codes and context maps",
        "Implement error unwrapping utilities",
        "Add retry logic hints",
        "Update error handling throughout codebase",
        "Tests for error behavior",
        "Documentation of error types and handling"
      ],
      "acceptanceCriteria": [
        "Structured errors are easy to inspect",
        "Error codes are meaningful and well-organized",
        "Context maps provide debugging information",
        "Unwrapping works correctly",
        "Retry hints are useful for callers",
        "Error handling is consistent",
        "Production debugging is significantly improved"
      ]
    },
    {
      "id": "T68",
      "title": "Improvement - Eventloop Fast Path Mode Transition Logging üîç",
      "description": "Add debug logging for fast path entry/exit events, mode transition triggers, and performance metrics comparison in eventloop/loop.go. This provides production debugging insight into performance regressions.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [
        "T25"
      ],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #10 Eventloop Fast Path Mode Transition Logging",
      "expectedImpact": "Production debugging insight into performance regressions",
      "deliverables": [
        "Add fast path entry logging (when entering fast path mode)",
        "Add fast path exit logging (when exiting fast path mode)",
        "Add mode transition trigger logging (why mode changed)",
        "Add performance metrics comparison (fast path vs normal path)",
        "Integrate with logiface.L",
        "Add configurable log levels",
        "Tests for logging behavior",
        "Documentation of fast path logging"
      ],
      "acceptanceCriteria": [
        "Fast path transitions are logged correctly",
        "Mode triggers are identifiable",
        "Performance metrics provide actionable insights",
        "No significant performance overhead from logging",
        "Logs are useful for production debugging",
        "All logging tests pass",
        "Performance regressions are detectable in logs"
      ]
    },
    {
      "id": "T69",
      "title": "Improvement - SQL Export Primary Key Ordering Validation ‚úÖ",
      "description": "Implement validation for result set primary key ordering in sql/export/export.go:401. Currently there is a TODO comment: 'sanity checking of result set primary key ordering'. This ensures data integrity and early detection of schema design errors.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #11 SQL Export Primary Key Ordering Validation",
      "expectedImpact": "Data integrity guarantee, early detection of schema design errors",
      "deliverables": [
        "Analyze current result set ordering behavior",
        "Design validation logic for primary key ordering",
        "Implement primary key ordering validation",
        "Add error messages for ordering violations",
        "Tests for correct ordering validation",
        "Tests for ordering violation detection",
        "Documentation of validation behavior",
        "Remove TODO comment"
      ],
      "acceptanceCriteria": [
        "Primary key ordering is validated correctly",
        "Ordering violations are detected with clear error messages",
        "Valid ordering passes validation without errors",
        "Performance overhead is minimal",
        "All validation tests pass",
        "Schema design errors are caught early",
        "TODO comment is removed"
      ]
    },
    {
      "id": "T70",
      "title": "Improvement - File Descriptor Registration Timeout ‚è±Ô∏è",
      "description": "Add timeout to FD registration operations in eventloop/poller.go and RegisterFD (loop.go:1290) to prevent indefinite blocking. Currently there is no timeout for FD registration operations which can cause production hangs on I/O path issues.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #12 File Descriptor Registration Timeout",
      "expectedImpact": "Production resilience against I/O path hangs",
      "deliverables": [
        "Analyze current FD registration flow",
        "Add timeout parameter to RegisterFD",
        "Implement timeout enforcement for FD registration",
        "Add callback or error handling for timeout",
        "Tests for timeout behavior",
        "Tests for normal registration behavior",
        "Documentation of timeout behavior"
      ],
      "acceptanceCriteria": [
        "FD registration enforces timeout correctly",
        "Timeout triggers appropriate error handling",
        "Normal registration works without issues",
        "No performance overhead for successful registrations",
        "All timeout tests pass",
        "I/O path hangs are prevented",
        "Error handling provides diagnostic information"
      ]
    },
    {
      "id": "T71",
      "title": "Improvement - Promise Memory Leak Detection Test üß™",
      "description": "Add regression test validating that promises are GC'd after settlement and registry doesn't hold strong references in eventloop/registry.go. This increases production confidence in memory management and improves coverage by +1-2%.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #13 Promise Memory Leak Detection Test",
      "expectedImpact": "Production confidence in memory management, +1-2% coverage",
      "deliverables": [
        "Test file: eventloop/registry_memory_leak_test.go",
        "Test for promise GC after settlement",
        "Test for registry not holding strong references",
        "Test for long-running applications with many promises",
        "Test for weak.Pointer behavior",
        "Memory profiling validation",
        "Documentation of memory management guarantees"
      ],
      "acceptanceCriteria": [
        "Settled promises are GC'd correctly",
        "Registry doesn't hold strong references",
        "Weak pointers work as expected",
        "Long-running applications don't leak memory",
        "All memory leak tests pass",
        "Coverage increases by 1-2%",
        "Memory management guarantees are documented"
      ]
    },
    {
      "id": "DOC01",
      "title": "Documentation - Advanced Metrics Usage Guide üìö",
      "description": "Create comprehensive documentation for advanced metrics usage including best practices for metrics interpretation. File: eventloop/docs/routing/ADVANCED_METRICS_USAGE.md",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [
        "T62"
      ],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #14-17 Documentation Gaps",
      "expectedImpact": "Improved developer experience, better production monitoring",
      "deliverables": [
        "Create eventloop/docs/routing/ADVANCED_METRICS_USAGE.md",
        "Document all available metrics",
        "Provide interpretation guidelines",
        "Include real-world examples",
        "Best practices for monitoring",
        "Common patterns and anti-patterns",
        "Performance tuning guidance"
      ],
      "acceptanceCriteria": [
        "Documentation is comprehensive and clear",
        "All metrics are documented with examples",
        "Interpretation guidelines are practical",
        "Real-world examples are relevant",
        "Best practices are actionable",
        "Anti-patterns help avoid common mistakes"
      ]
    },
    {
      "id": "DOC02",
      "title": "Documentation - Promise Anti-Patterns Guide üìö",
      "description": "Create comprehensive guide for anti-patterns to avoid with promises. File: eventloop/docs/routing/ANTIPATTERNS.md",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #14-17 Documentation Gaps",
      "expectedImpact": "Improved developer experience, fewer production issues",
      "deliverables": [
        "Create eventloop/docs/routing/ANTIPATTERNS.md",
        "Document common promise anti-patterns",
        "Explain why each pattern is problematic",
        "Provide correct alternatives",
        "Include code examples of wrong vs right approaches",
        "Performance implications of anti-patterns",
        "Debugging anti-patterns in production"
      ],
      "acceptanceCriteria": [
        "Common anti-patterns are identified",
        "Explanations are clear and convincing",
        "Alternatives are practical and improve code",
        "Code examples are illustrative",
        "Performance implications are documented",
        "Debugging guidance is actionable"
      ]
    },
    {
      "id": "DOC03",
      "title": "Documentation - Platform-Specific Notes üìö",
      "description": "Create comprehensive documentation of epoll/kqueue/IOCP behavioral differences. File: eventloop/docs/routing/PLATFORM_NOTES.md",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #14-17 Documentation Gaps",
      "expectedImpact": "Improved cross-platform development, fewer platform-specific bugs",
      "deliverables": [
        "Create eventloop/docs/routing/PLATFORM_NOTES.md",
        "Document Linux epoll behavior",
        "Document Darwin/kqueue behavior",
        "Document Windows/IOCP behavior",
        "Explain key differences",
        "Platform-specific edge cases",
        "Best practices for cross-platform code",
        "Troubleshooting platform-specific issues"
      ],
      "acceptanceCriteria": [
        "Each platform's behavior is clearly documented",
        "Differences are highlighted",
        "Edge cases are explained with examples",
        "Best practices are actionable",
        "Troubleshooting guidance helps real issues",
        "Cross-platform developers can write correct code"
      ]
    },
    {
      "id": "DOC04",
      "title": "Documentation - Goja Performance Tuning Guide üìö",
      "description": "Create comprehensive performance tuning guide for balancing Goja overhead vs eventloop performance. File: goja-eventloop/docs/PERFORMANCE_TUNING.md",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #14-17 Documentation Gaps",
      "expectedImpact": "Improved developer experience, better performance optimization",
      "deliverables": [
        "Create goja-eventloop/docs/PERFORMANCE_TUNING.md",
        "Document Goja overhead sources",
        "Document eventloop performance characteristics",
        "Explain trade-offs in integration",
        "Provide tuning guidelines",
        "Include benchmarks and examples",
        "Profile-driven optimization techniques",
        "Common performance pitfalls"
      ],
      "acceptanceCriteria": [
        "Goja overhead sources are clearly explained",
        "Trade-offs are well-articulated",
        "Tuning guidelines are practical",
        "Examples illustrate key concepts",
        "Benchmarks provide actionable data",
        "Optimization techniques are effective",
        "Developers can make informed decisions"
      ]
    },
    {
      "id": "T72",
      "title": "Test Coverage - Concurrent Promise Creation üß™",
      "description": "Add comprehensive tests for concurrent promise creation covering all edge cases and race conditions.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #18-23 Test Coverage Gaps",
      "expectedImpact": "Detection of obscure bugs, improved production confidence",
      "deliverables": [
        "Test file: eventloop/promise_concurrent_creation_test.go",
        "Tests for concurrent promise creation",
        "Tests for concurrent promise resolution",
        "Tests for concurrent promise rejection",
        "Tests under high contention",
        "Race condition tests",
        "Stress tests"
      ],
      "acceptanceCriteria": [
        "All concurrent tests pass",
        "No data races detected with -race flag",
        "Production confidence increased",
        "Edge cases covered",
        "High contention scenarios tested"
      ]
    },
    {
      "id": "T73",
      "title": "Test Coverage - Timer Cancellation Races üß™",
      "description": "Add comprehensive tests for timer cancellation race conditions covering all edge cases.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #18-23 Test Coverage Gaps",
      "expectedImpact": "Detection of obscure bugs, improved production confidence",
      "deliverables": [
        "Test file: eventloop/timer_cancellation_races_test.go",
        "Tests for timer cancellation during execution",
        "Tests for timer cancellation during scheduling",
        "Tests for timer cancellation after completion",
        "Tests for concurrent timer cancellation",
        "Race condition tests",
        "Edge case tests"
      ],
      "acceptanceCriteria": [
        "All timer cancellation tests pass",
        "No data races detected with -race flag",
        "Production confidence increased",
        "Edge cases covered",
        "Race scenarios tested"
      ]
    },
    {
      "id": "T74",
      "title": "Test Coverage - Registry Scavenge Performance üß™",
      "description": "Add performance tests for registry scavenging to ensure efficient cleanup and detect any performance regressions.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #18-23 Test Coverage Gaps",
      "expectedImpact": "Detection of performance issues, optimization validation",
      "deliverables": [
        "Test file: eventloop/registry_scavenge_performance_test.go",
        "Benchmark tests for registry scavenge",
        "Tests for large registry cleanup",
        "Tests for frequent scavenging",
        "Memory allocation analysis",
        "Performance regression tests"
      ],
      "acceptanceCriteria": [
        "All performance tests pass",
        "Scavenge performance is acceptable",
        "No performance regressions detected",
        "Memory allocations are efficient",
        "Large registry cleanup works correctly"
      ]
    },
    {
      "id": "T75",
      "title": "Test Coverage - Platform-Specific Poll Edge Cases üß™",
      "description": "Add tests for platform-specific poller edge cases covering epoll, kqueue, and IOCP differences.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #18-23 Test Coverage Gaps",
      "expectedImpact": "Detection of platform-specific bugs, improved platform confidence",
      "deliverables": [
        "Test file: eventloop/poller_platform_edge_cases_test.go",
        "Linux epoll edge case tests",
        "Darwin kqueue edge case tests",
        "Windows IOCP edge case tests",
        "Cross-platform comparison tests",
        "Platform-specific behavior validation"
      ],
      "acceptanceCriteria": [
        "All platform-specific tests pass",
        "Edge cases covered for all platforms",
        "Platform differences documented",
        "No platform-specific bugs found",
        "Cross-platform tests are consistent"
      ]
    },
    {
      "id": "T76",
      "title": "Test Coverage - Goja Iterator Protocol Stress üß™",
      "description": "Add comprehensive stress tests for Goja iterator protocol handling to ensure robust custom iterator support.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #18-23 Test Coverage Gaps",
      "expectedImpact": "Detection of iterator bugs, production confidence",
      "deliverables": [
        "Test file: goja-eventloop/iterator_stress_test.go",
        "Stress tests for custom iterators",
        "Tests for malformed iterators",
        "Tests for infinite iterators",
        "Tests for concurrent iterator access",
        "Edge case tests"
      ],
      "acceptanceCriteria": [
        "All iterator stress tests pass",
        "Malformed iterators handled correctly",
        "Infinite iterators don't cause hangs",
        "Concurrent access is safe",
        "Production confidence increased"
      ]
    },
    {
      "id": "T77",
      "title": "Test Coverage - Chunked Ingress Batch Pop Performance üß™",
      "description": "Add performance tests for chunked ingress batch pop operations to validate efficiency.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #18-23 Test Coverage Gaps",
      "expectedImpact": "Detection of performance issues, optimization validation",
      "deliverables": [
        "Test file: eventloop/chunked_ingress_perf_test.go",
        "Benchmark tests for batch pop",
        "Tests for large batch sizes",
        "Tests for concurrent batch pop",
        "Memory allocation analysis",
        "Performance regression tests"
      ],
      "acceptanceCriteria": [
        "All performance tests pass",
        "Batch pop performance is optimal",
        "No performance regressions",
        "Memory allocations are efficient",
        "Large batch operations work correctly"
      ]
    },
    {
      "id": "T78",
      "title": "Performance - Metrics Sampling Overhead Reduction üìä",
      "description": "Reduce metrics sampling overhead by 50-70% (from current 100-200 Œºs per sample to 30-60 Œºs) in eventloop/metrics.go using histogram-based approximation (O(1) sampling) instead of O(n log n) sort.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #25 Metrics Sampling Overhead Reduction",
      "expectedImpact": "50-70% reduction in metrics overhead (~100-200 Œºs ‚Üí ~30-60 Œºs per sample)",
      "deliverables": [
        "Analyze current O(n log n) implementation",
        "Design O(1) histogram-based algorithm",
        "Implement histogram-based sampling",
        "Benchmark new vs old implementation",
        "Validate statistical accuracy",
        "Regression tests",
        "Documentation of performance improvement"
      ],
      "acceptanceCriteria": [
        "Sampling overhead reduced by 50-70%",
        "Statistical accuracy maintained",
        "No regressions in metrics quality",
        "All benchmarks show improvement",
        "Regression tests pass",
        "Implementation is maintainable"
      ]
    },
    {
      "id": "T79",
      "title": "Performance - Microtask Ring Buffer Adaptive Sizing üì•",
      "description": "Implement adaptive sizing for microtask ring buffer in eventloop/ring.go (line 17: ringBufferSize = 4096). Start at 1024, double until overflow detected. This reduces memory usage by 50% for small workloads.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #26 Microtask Ring Buffer Adaptive Sizing",
      "expectedImpact": "50% memory reduction for small workloads",
      "deliverables": [
        "Design adaptive sizing algorithm",
        "Implement starting size 1024",
        "Implement doubling on overflow",
        "Implement maximum size limit",
        "Benchmark memory usage",
        "Performance tests",
        "Documentation of adaptive behavior"
      ],
      "acceptanceCriteria": [
        "Memory reduced by 50% for small workloads",
        "Adaptive sizing works correctly",
        "Overflow triggers doubling appropriately",
        "No performance regressions",
        "All tests pass",
        "Behavior is documented"
      ]
    },
    {
      "id": "T80",
      "title": "Performance - Goja Value Caching for Frequent Access üóÑÔ∏è",
      "description": "Implement LRU cache for exported Go types in goja-eventloop/adapter.go to reduce Goja value conversion overhead by 20-40%. Use map[any]goja.Value for LRU cache and weak references for GC.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #27 Goja Value Caching for Frequent Access",
      "expectedImpact": "20-40% reduction in Goja value conversion overhead",
      "deliverables": [
        "Design LRU cache structure",
        "Implement cache for exported Go types",
        "Implement cache size limits",
        "Implement weak references for GC",
        "Benchmark cache hit rates",
        "Performance tests",
        "Cache invalidation logic",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "Conversion overhead reduced by 20-40%",
        "Cache improves performance for repeated conversions",
        "Weak references prevent memory leaks",
        "Cache size limits prevent unbounded growth",
        "All benchmarks show improvement",
        "No regressions in functionality"
      ]
    },
    {
      "id": "T81",
      "title": "Performance - Promise Handler Batching Microtask Reduction üì•",
      "description": "Batch handler execution for promises in eventloop/promise.go to reduce microtask scheduling overhead by 10-30%. Collect all pending handlers for same promise, execute as single microtask. Must maintain Promise/A+ spec compliance.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #28 Promise Handler Batching Microtask Reduction",
      "expectedImpact": "10-30% reduction in microtask scheduling overhead",
      "deliverables": [
        "Design batching algorithm",
        "Collect handlers for same promise",
        "Execute as single microtask",
        "Ensure Promise/A+ compliance",
        "Test batching behavior",
        "Benchmark performance improvement",
        "Regression tests",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "Microtask overhead reduced by 10-30%",
        "Promise/A+ compliance maintained",
        "Handler execution order preserved",
        "All tests pass",
        "Benchmarks show improvement",
        "No regressions in behavior"
      ]
    },
    {
      "id": "T82",
      "title": "Security - Event Loop Sandbox Mode üõ°",
      "description": "Add sandbox mode for production defense against untrusted code and DoS prevention. Implement WithSandbox(SandboxConfig) option with max execution time per task, max concurrent tasks, max promise depth, max loop depth.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #36 Event Loop Sandbox Mode",
      "expectedImpact": "Production defense against untrusted code, DoS prevention",
      "deliverables": [
        "Design SandboxConfig structure",
        "Implement max execution time per task",
        "Implement max concurrent tasks limit",
        "Implement max promise depth limit",
        "Implement max loop depth limit",
        "Implement WithSandbox LoopOption",
        "Tests for sandbox enforcement",
        "Tests for sandbox bypass attempts",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "Sandbox limits are enforced correctly",
        "Malicious code is contained",
        "DoS attempts are prevented",
        "Performance overhead for trusted code is minimal",
        "All sandbox tests pass",
        "Bypass attempts are detected",
        "Documentation is clear"
      ]
    },
    {
      "id": "T83",
      "title": "Security - Promise Sensitive Data Redaction üîí",
      "description": "Add sensitive data redaction for production security and PCI-DSS/GDPR compliance. Implement WithSensitiveDataPattern(pattern, replacement) option to redact matching patterns in promise results before logging.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [
        "T25"
      ],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #37 Promise Sensitive Data Redaction",
      "expectedImpact": "Production security, PCI-DSS/GDPR compliance",
      "deliverables": [
        "Design pattern matching system",
        "Implement WithSensitiveDataPattern option",
        "Redact logs and error messages",
        "Support multiple patterns",
        "Test redaction behavior",
        "Test pattern matching accuracy",
        "Performance tests",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "Sensitive data is redacted correctly",
        "Multiple patterns supported",
        "Patterns are applied consistently",
        "Performance overhead is minimal",
        "All tests pass",
        "Compliance requirements met"
      ]
    },
    {
      "id": "T84",
      "title": "Observability - Structured Error Correlation IDs üîó",
      "description": "Generate unique error ID at creation (UUID v7), propagate through error wrapping chain. This improves production debugging efficiency by 5-10x.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #38 Structured Error Correlation IDs",
      "expectedImpact": "Production debugging efficiency 5-10x improvement",
      "deliverables": [
        "Implement UUID v7 generation",
        "Add correlation ID to errors",
        "Propagate through wrapping chain",
        "Implement error lookup by ID",
        "Tests for correlation ID behavior",
        "Tests for propagation",
        "Documentation",
        "Integration with logging"
      ],
      "acceptanceCriteria": [
        "Each error has unique correlation ID",
        "Correlation IDs propagate correctly",
        "Errors can be traced across async operations",
        "UUID v7 format is correct",
        "All tests pass",
        "Production debugging improved"
      ]
    },
    {
      "id": "T85",
      "title": "Observability - Audit Log for Timer Operations üìã",
      "description": "Add audit logging capability for timer operations for forensic investigation and audit compliance. Implement WithAuditLogger(logger AuditLogger) option to log all timer operations with timestamps.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [
        "T25"
      ],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #39 Audit Log for Timer Operations",
      "expectedImpact": "Forensic investigation capability, audit compliance",
      "deliverables": [
        "Design AuditLogger interface",
        "Implement WithAuditLogger option",
        "Log timer create operations",
        "Log timer cancel operations",
        "Log timer fire operations",
        "Include timestamps and metadata",
        "Tests for audit logging",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "All timer operations are logged",
        "Logs include timestamps and metadata",
        "Audit logger is configurable",
        "Performance overhead is minimal",
        "All tests pass",
        "Audit compliance requirements met"
      ]
    },
    {
      "id": "T86",
      "title": "Observability - CPU Time Tracking per Task ‚öôÔ∏è",
      "description": "Track CPU time consumed by each task to provide production performance insight (compute-bound vs IO-bound tasks). Use runtime.SetFinalizer to measure CPU consumed and report vs wall-clock latency.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #40 CPU Time Tracking per Task",
      "expectedImpact": "Production performance insight (compute-bound vs IO-bound tasks)",
      "deliverables": [
        "Design CPU tracking mechanism",
        "Implement runtime.SetFinalizer integration",
        "Track CPU per task",
        "Report CPU vs wall-clock latency",
        "Metrics integration",
        "Tests for CPU tracking accuracy",
        "Performance impact tests",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "CPU time is tracked accurately",
        "Compute-bound vs IO-bound tasks identifiable",
        "Metrics provide useful insights",
        "Overhead is minimal",
        "All tests pass",
        "Production performance improved"
      ]
    },
    {
      "id": "T87",
      "title": "Production Stability - Rate Limiting Integration üö¶",
      "description": "Add rate limiting integration for admission control in eventloop/ingress.go to ensure production stability under load spikes and graceful degradation. Implement WithAdmissionControl(AdmissionControl) option with max tasks-per-second rate limit and max queue depth limit.",
      "status": "not-started",
      "priority": "P2",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #41 Rate Limiting Integration",
      "expectedImpact": "Production stability under load spikes, graceful degradation",
      "deliverables": [
        "Design AdmissionControl interface",
        "Implement token bucket rate limiter",
        "Implement max tasks-per-second limit",
        "Implement max queue depth limit",
        "Implement WithAdmissionControl option",
        "Tests for rate limiting",
        "Tests for graceful degradation",
        "Documentation"
      ],
      "acceptanceCriteria": [
        "Rate limits are enforced correctly",
        "Queue depth limits prevent overflow",
        "Graceful degradation works",
        "System remains stable under load",
        "All tests pass",
        "Production stability improved"
      ]
    },
    {
      "id": "API01",
      "title": "API - Loop Context Propagation Hook üîó",
      "description": "Add context propagation hook for automatic context inheritance. Implement WithTaskContextHook(func(taskContext) context.Context) option.",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #29 Loop Context Propagation Hook",
      "expectedImpact": "Improved developer experience, better context handling",
      "deliverables": [
        "Design TaskContextHook interface",
        "Implement WithTaskContextHook option",
        "Apply hook to all tasks",
        "Tests for context propagation",
        "Tests for context cancellation",
        "Documentation",
        "Examples"
      ],
      "acceptanceCriteria": [
        "Context propagates correctly",
        "Hook allows customization",
        "Cancellation works as expected",
        "All tests pass",
        "API is intuitive"
      ]
    },
    {
      "id": "API02",
      "title": "API - Promise Error Type Assertion Helper üéØ",
      "description": "Add utility function for cleaner error handling. Implement promise.ResultAsError() error, ok helper.",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #30 Promise Error Type Assertion Helper",
      "expectedImpact": "Improved developer experience, cleaner error handling",
      "deliverables": [
        "Implement ResultAsError() method",
        "Return error, ok for type assertion",
        "Tests for error extraction",
        "Tests for non-error values",
        "Documentation",
        "Examples"
      ],
      "acceptanceCriteria": [
        "Error extraction works correctly",
        "Type assertions are safe",
        "API is intuitive to use",
        "All tests pass",
        "Code is cleaner than alternatives"
      ]
    },
    {
      "id": "DOC05",
      "title": "Documentation - Timer ID Reuse Policy üìã",
      "description": "Document timer ID reuse policy behavior after MAX_SAFE_INTEGER exceeded and recommended reset strategy in README.md.",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #31 Timer ID Reuse Policy Documentation",
      "expectedImpact": "Improved developer understanding, fewer bugs in production",
      "deliverables": [
        "Document timer ID allocation strategy",
        "Document MAX_SAFE_INTEGER behavior",
        "Document behavior after overflow",
        "Document recommended reset strategy",
        "Add examples",
        "Update README.md"
      ],
      "acceptanceCriteria": [
        "ID behavior is clearly explained",
        "Overflow behavior is documented",
        "Reset strategy is practical",
        "Examples are helpful",
        "README update is comprehensive"
      ]
    },
    {
      "id": "API03",
      "title": "API - Metrics Sampling Control API üéöÔ∏è",
      "description": "Add dynamic control for metrics sampling. Implement loop.SetMetricsEnabled(enabled bool, samplingInterval) API.",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #32 Metrics Sampling Control API",
      "expectedImpact": "Improved runtime control, better observability management",
      "deliverables": [
        "Implement SetMetricsEnabled method",
        "Enable/disable metrics dynamically",
        "Control sampling interval",
        "Thread-safe implementation",
        "Tests for API behavior",
        "Tests for dynamic control",
        "Documentation",
        "Examples"
      ],
      "acceptanceCriteria": [
        "Metrics can be enabled/disabled dynamically",
        "Sampling interval is controllable",
        "API is thread-safe",
        "All tests pass",
        "API is intuitive"
      ]
    },
    {
      "id": "API04",
      "title": "API - Promise Handler Execution Stack Trace Capture üîç",
      "description": "Add stack trace capture for production debugging. Implement WithHandlerStackTrace(enabled bool, depth int) option.",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #34 Promise Handler Execution Stack Trace Capture",
      "expectedImpact": "Improved production debugging, better error context",
      "deliverables": [
        "Implement WithHandlerStackTrace option",
        "Capture execution stacks",
        "Control trace depth",
        "Include stack in errors",
        "Tests for stack capture",
        "Performance impact tests",
        "Documentation",
        "Examples"
      ],
      "acceptanceCriteria": [
        "Stack traces are captured correctly",
        "Depth control works",
        "Stacks provide useful context",
        "Performance overhead is acceptable",
        "All tests pass",
        "Production debugging improved"
      ]
    },
    {
      "id": "API05",
      "title": "API - Goja Runtime Lifecycle Hook üóÑÔ∏è",
      "description": "Add lifecycle hooks for Goja runtime. Implement WithRuntimeHook(RuntimeLifecycle) option with OnRuntimeCreated/Shutdown/CycleStart/End events.",
      "status": "not-started",
      "priority": "P3",
      "critical": false,
      "dependsOn": [],
      "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md #35 Goja Runtime Lifecycle Hook",
      "expectedImpact": "Improved observability, better integration control",
      "deliverables": [
        "Design RuntimeLifecycle interface",
        "Implement OnRuntimeCreated callback",
        "Implement OnRuntimeShutdown callback",
        "Implement OnCycleStart callback",
        "Implement OnCycleEnd callback",
        "Implement WithRuntimeHook option",
        "Tests for lifecycle events",
        "Tests for hook behavior",
        "Documentation",
        "Examples"
      ],
      "acceptanceCriteria": [
        "All lifecycle events fire correctly",
        "Hooks are called in order",
        "API is flexible and extensible",
        "All tests pass",
        "Observability improved"
      ]
    }
  ],
  "continuousVerification": {
    "task": "Run 'make all' with full logging after EVERY significant change",
    "description": "Execute 'make all 2>&1 | fold -w 200 | tee build.log | tail -n 15' after: (a) Each code change, (b) Each test addition, (c) Each task completion, (d) Each bug fix, (e) Each review cycle. This is a CONTINUOUS task that must be executed throughout the entire plan without exception.",
    "failPolicy": "If ANY test fails, STOP IMMEDIATELY and fix the issue before proceeding. Zero tolerance for test failures, timing issues, non-determinism, or race conditions. Do not skip, defer, or ignore any test failure.",
    "baseline": {
      "date": "2026-01-28",
      "platforms": [
        "macOS",
        "linux-container"
      ],
      "result": "ALL_PASS (200+ tests)",
      "duration": "83.747s (macOS), 137.480s (linux)",
      "status": "baseline-verified-healthy"
    }
  },
  "documentation": {
    "sourceDocument": "eventloop/docs/routing/improvements-roadmap.md (DELETED - synced 2026-01-30)",
    "lastSynced": "2026-01-30T00:00:00Z",
    "syncStatus": "COMPLETE",
    "warnings": "Source document marked for deletion by user. ALL 57 improvements now in blueprint.json.",
    "roadmapStatus": {
      "productionReady": true,
      "confidenceLevel": "96-97%",
      "reviewsCompleted": 4,
      "totalImprovementsIdentified": 57,
      "summary": "The eventloop module and its integration with goja-eventloop have undergone comprehensive review through 4 independent verification passes. The verdict is unanimous across all reviews: the codebase is production-ready with 96-97% confidence. However, 57 specific improvement opportunities have been identified that would elevate the system from 'production-ready' to 'best-in-class'."
    },
    "whatsExcellent": {
      "T42": {
        "title": "Cache Line Alignment Optimization ‚ö°",
        "status": "PERFECT",
        "description": "All hot structures manually aligned. betteralign verified no changes required. Impact: Zero false sharing, optimal performance under contention."
      },
      "T43": {
        "title": "Timer Pool Implementation üóÑÔ∏è",
        "status": "EXCELLENT",
        "description": "Zero-allocation hot path. sync.Pool usage, proper reset before return. Impact: 200-500 ns/op timer scheduling."
      },
      "T44": {
        "title": "Weak Pointer-Based Promise Registry üóÑÔ∏è",
        "status": "EXCELLENT",
        "description": "GC-friendly design prevents memory leaks. weak.Pointer usage allows settled promises to be collected. Impact: No unbounded memory growth, correct behavior for long-running applications."
      },
      "T45": {
        "title": "Promise/A+ Specification Compliance ‚úÖ",
        "status": "COMPREHENSIVE",
        "description": "All required features implemented correctly. Full Then/Catch/Finally support, combinators (All, Race, AllSettled, Any). Impact: JavaScript compatibility, correct async semantics."
      },
      "T46": {
        "title": "Platform-Specific Poller Implementations üíª",
        "status": "ROBUST",
        "description": "Native I/O for each platform. epoll (Linux), kqueue (Darwin/BSD), IOCP (Windows). Impact: Maximum I/O performance, correct platform-specific behaviors."
      },
      "T47": {
        "title": "Comprehensive Test Suite üß™",
        "status": "EXCEPTIONAL",
        "description": "200+ tests covering all critical paths. Race-condition tests, stress tests, regression tests. Impact: High confidence in correctness, production readiness."
      },
      "T48": {
        "title": "Fast Path Optimization ‚ö°",
        "status": "EFFECTIVE",
        "description": "Zero I/O FD path optimized. Automatic mode selection, channel-based wakeups. Impact: 50-80% latency reduction for pure-async workloads."
      },
      "T49": {
        "title": "Atomic Operations Correctness üîê",
        "status": "VERIFIED",
        "description": "No incorrect Store() calls, proper CAS usage. State machine transitions validated. Impact: Race-free implementation, deterministic behavior."
      },
      "T50": {
        "title": "Documentation Quality üìö",
        "status": "STRONG",
        "description": "Clear README with examples. Comprehensive usage examples for all major features. Impact: Developer onboarding efficiency."
      }
    },
    "implementationPhases": {
      "phase1": {
        "title": "Phase 1: Quick Wins",
        "tasks": ["T25", "T61", "T28"],
        "description": "Initial high-impact improvements with minimal implementation investment.",
        "status": "not-started"
      },
      "phase2": {
        "title": "Phase 2: Priorities",
        "tasks": ["T62", "T63", "T64", "T65", "T66", "T67", "T68"],
        "description": "High-priority enhancements and improvements.",
        "status": "not-started"
      },
      "phase3": {
        "title": "Phase 3: SECURITY & OBSERVABILITY",
        "tasks": ["T82", "T83", "T84", "T85", "T86", "T87"],
        "description": "Security hardening and observability enhancements.",
        "status": "not-started"
      },
      "phase4": {
        "title": "Phase 4: API/UX IMPROVEMENTS",
        "tasks": ["API01", "API02", "DOC05", "API03", "T64", "API04", "API05", "T68"],
        "description": "User experience improvements and API enhancements.",
        "status": "not-started"
      },
      "phase5": {
        "title": "Phase 5: DOCUMENTATION",
        "tasks": ["DOC01", "DOC02", "DOC03", "DOC04", "DOC05"],
        "description": "Comprehensive documentation expansion.",
        "status": "not-started"
      },
      "phase6": {
        "title": "Phase 6: PERFORMANCE OPTIMIZATIONS",
        "tasks": ["T78", "T79", "T80", "T81"],
        "description": "Performance optimizations after testing and coverage improvements.",
        "status": "not-started"
      }
    },
    "confidenceAssessment": {
      "overallProductionReadiness": "96-97%",
      "justification": [
        "Correctness: Zero critical bugs found in 4 exhaustive reviews; atomic operations, state machine, weak pointer usage all verified correct",
        "Performance: Cache alignment and timer pooling demonstrate deep optimization; benchmark results show best-in-class latencies",
        "Testing: 200+ tests with -race detector clean; edge cases covered; stress tests pass",
        "Architecture: Modular design with clean separation of concerns",
        "Platform Support: Native I/O for all three major platforms (epoll, kqueue, IOCP)"
      ],
      "areasRequiringDeeperInvestigation": [
        "Lock contention under extreme producer load (disputed - tournament shows Main is superior)",
        "Metrics sampling interval quantification (no benchmark data for 100-200Œºs claim)",
        "Goja integration edge cases (custom iterators and malicious inputs tested but not fully validated)"
      ]
    }
  }
}